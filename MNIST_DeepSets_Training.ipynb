{
  "cells": [
    {
      "metadata": {
        "id": "-H2bBxqJriZL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": "**Initialization**"
    },
    {
      "metadata": {
        "id": "jSTczZvdrm-B",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": "Imports"
    },
    {
      "metadata": {
        "id": "HOkW4QleqoCy",
        "colab_type": "code",
        "colab": {},
        "trusted": true
      },
      "cell_type": "code",
      "source": "import tensorflow as tf\nfrom tensorflow import keras\nimport numpy as np",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5F6IrlBXroxL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": "Hyperparameters"
    },
    {
      "metadata": {
        "id": "WwKAIQHCrsIg",
        "colab_type": "code",
        "colab": {},
        "trusted": true
      },
      "cell_type": "code",
      "source": "n_epoch = 250\nbatch_size = 50\nthreshold = 128\nlearning_rate = 0.0001\n\n\ninput_feature_dimension = 2\nhidden_feature_dimension = 5\noutput_feature_dimension = 10",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nJjA97ror0bY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": "Import MNIST"
    },
    {
      "metadata": {
        "id": "hp8vAG1Mr6mF",
        "colab_type": "code",
        "colab": {},
        "trusted": true
      },
      "cell_type": "code",
      "source": "mnist = keras.datasets.mnist\n(training_images, training_labels), (test_images, test_labels) = mnist.load_data()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZxzDGznMr80o",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": "**Data formatting**"
    },
    {
      "metadata": {
        "id": "wqDi6lGzr_ve",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": "Method for calculating maximum set size"
    },
    {
      "metadata": {
        "id": "EoCikIxksDhY",
        "colab_type": "code",
        "colab": {},
        "trusted": true
      },
      "cell_type": "code",
      "source": "def decrease_set_size():\n    max_count = 0\n    for i in range (60000):\n        count = 0\n        for j1 in range (28):\n            for j2 in range (28):\n                if training_images[i][j1][j2] >= 1:\n                    count += 1\n        if count > max_count:\n            max_count = count\n      \n    for i in range (10000):\n        count = 0\n        for j1 in range (28):\n            for j2 in range (28):\n                if training_images[i][j1][j2] >= 1:\n                    count += 1\n        if count > max_count:\n            max_count = count\n      \n    return max_count",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KzO9Taa8uLgV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": "Methods for formatting the dataset to coordinate sets with a mask."
    },
    {
      "metadata": {
        "id": "r-X4c6vkuJ6z",
        "colab_type": "code",
        "colab": {},
        "trusted": true
      },
      "cell_type": "code",
      "source": "def format_data(image):\n    data = []\n    mask = []\n    for i in range(28):\n        for j in range(28):\n            if image[i][j] > threshold:\n                data.append([i, j])\n                mask.append(1)\n    for k in range(max_set_size - len(data)):\n        data.append([0,0])\n        mask.append(0)\n    dataArray = np.array(data)\n    maskArray = np.array(mask)\n    return unison_shuffle(dataArray, maskArray)\n\ndef unison_shuffle(data, mask):\n    assert len(data) == len(mask)\n    p = np.random.permutation(len(data))\n    return data[p], mask[p]\n\ndef generate_images(images):\n    image_array = ([])\n    mask_array = ([])\n    for i in range(len(images)):\n        img = images[i]\n        data, mask = format_data(img)\n        image_array.append(data)\n        mask_array.append(mask)\n    return np.array(image_array), np.array(mask_array)\n\ndef format_label(labels):\n    label_array = []\n    for i in range(len(labels)):\n        label = np.zeros(10)\n        label[labels[i]] = 1\n        label_array.append(label)\n    return np.array(label_array)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xT-7Gnva6ebz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": "Calculate training data, test data along with their masks and labels using the previously defined methods."
    },
    {
      "metadata": {
        "id": "1rN59X3Y56fk",
        "colab_type": "code",
        "colab": {},
        "trusted": true
      },
      "cell_type": "code",
      "source": "max_set_size = decrease_set_size()\n\ntraining_data, training_mask = generate_images(training_images)\ntest_data, test_mask = generate_images(test_images)\ntraining_label = format_label(training_labels)\ntest_label = format_label(test_labels)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MilLp5Qj6BIp",
        "colab_type": "code",
        "outputId": "b73e8507-0dbe-4a41-c3d9-f3658186d7b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(\"Set size             =  \", max_set_size)\n\nprint(\"Training data shape  = \", training_data.shape,\n     \"\\nTest data shape      = \", test_data.shape,\n     \"\\nTraining label shape = \", training_label.shape,\n     \"\\nTest label shape     = \", test_label.shape)\n\nprint(\"Training mask shape  = \", training_mask.shape,\n     \"\\nTest mask shape      = \", test_mask.shape)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SyNKzfp597bf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": "**The network**"
    },
    {
      "metadata": {
        "id": "Warak7jy9-PJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": "Structure"
    },
    {
      "metadata": {
        "id": "z81BRnpoAi05",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "outputId": "7fe09ebc-1243-4bde-e8fa-4955e7037f10",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Update this string when altering the network\nnetwork_stats = '100-200-100-SIGMA-100-100-100-10'\n\n# Initialization of input, output and mask shapes\nx = tf.placeholder(tf.float32, [None, max_set_size, input_feature_dimension])\ny = tf.placeholder(tf.float32, [None, output_feature_dimension])\nx_mask = tf.placeholder(tf.bool, [None, max_set_size])\n\n\n# The phi network:\n\nphi_hidden_1 = tf.layers.dense(inputs=x, units=100, activation=tf.nn.relu)\nphi_hidden_2 = tf.layers.dense(inputs=phi_hidden_1, units=200, activation=tf.nn.relu)\nphi_hidden_3 = tf.layers.dense(inputs=phi_hidden_2, units=100, activation=tf.nn.relu)\n#phi_hidden_4 = tf.layers.dense(inputs=phi_hidden_3, units=300, activation=tf.nn.relu)\n#phi_hidden_5 = tf.layers.dense(inputs=phi_hidden_4, units=300, activation=tf.nn.relu)\nphi = tf.layers.dense(inputs=phi_hidden_3, units=hidden_feature_dimension)\n\n\n# Mask and summation\n\nx_mask_hidden = tf.cast(tf.expand_dims(x_mask, -1), tf.float32)\nphi_masked = tf.multiply(x_mask_hidden, phi)\nSigma = tf.reduce_sum(phi_masked, axis=1, name=\"Sigma\")\n\n\n# The rho network:\n\nrho_hidden_1 = tf.layers.dense(inputs=Sigma, units=100, activation=tf.nn.relu)\nrho_hidden_2 = tf.layers.dense(rho_hidden_1, 100 , tf.nn.relu)\nrho_hidden_3 = tf.layers.dense(rho_hidden_2, 100, tf.nn.relu)\n#rho_hidden_4 = tf.layers.dense(rho_hidden_3, 300, tf.nn.relu)\ny_hat = tf.layers.dense(inputs=rho_hidden_3, units=output_feature_dimension)\ny_hat_softmax = tf.nn.softmax(y_hat)\ny_pred = tf.argmax(y_hat, axis=1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "N5Z2CGkp6nGL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": "Loss function and optimizer is defined"
    },
    {
      "metadata": {
        "id": "1k1jX1p16kAE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "bfc17205-7fa5-4900-ae26-0c9d7448a47f",
        "trusted": true
      },
      "cell_type": "code",
      "source": "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y, logits=y_hat))\noptimize = tf.train.AdamOptimizer(learning_rate).minimize(loss)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "c1HCZoQk6snH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": "A method for calculating the correct prediction percentage of the network is defined here."
    },
    {
      "metadata": {
        "id": "TsZ-K31P6mlt",
        "colab_type": "code",
        "colab": {},
        "trusted": true
      },
      "cell_type": "code",
      "source": "def predictions(output, labels):\n    correct = 0;\n    for i in range (output.size):\n        if output[i] == labels[i]:\n            correct = correct + 1\n    percentage = str(correct/output.size*100)\n    return (\"Correct: \" + percentage + \"%\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dpQuX2CVaSm1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": "**Running the network**"
    },
    {
      "metadata": {
        "id": "cIkPCqbwaVaQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": "Training the network"
    },
    {
      "metadata": {
        "id": "3j7tl1h-X7YT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "f248a101-ea01-40a4-c8a8-a111104f1aab",
        "trusted": true,
        "scrolled": true
      },
      "cell_type": "code",
      "source": "with tf.train.MonitoredSession() as sess:\n    for epoch in range(n_epoch):\n\n        for i in range(training_data.shape[0]//batch_size):\n            sess.run(optimize, {x: training_data[i*batch_size:(i+1)*batch_size], \n                                x_mask: training_mask[i*batch_size:(i+1)*batch_size], \n                                y: training_label[i*batch_size:(i+1)*batch_size]})\n            \n            test_loss = \\\n                sess.run(loss, {x:training_data[i*batch_size:(i+1)*batch_size], \n                                x_mask: training_mask[i*batch_size:(i+1)*batch_size], \n                                y: training_label[i*batch_size:(i+1)*batch_size]})\n\n        phi_val, y_val, y_pred_val = \\\n            sess.run([phi_masked, y_hat_softmax, y_pred], {x: test_data, x_mask: test_mask})\n        print('Epoch: ' , epoch, ' - Loss: ', str(test_loss))\n        if ((epoch % 10) == 0):\n            pred = predictions(y_pred_val, test_labels)\n            print(pred)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AZmxkHCmaovb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": "Displaying the results"
    },
    {
      "metadata": {
        "id": "mqi4zcJ2Yx4t",
        "colab_type": "code",
        "colab": {},
        "trusted": true
      },
      "cell_type": "code",
      "source": "ID_string = \\\n    str(network_stats) + \\\n    \".-E\" + str(n_epoch) + \\\n    \"-BS\" + str(batch_size) + \\\n    \"-LR\" + str(learning_rate) + \\\n    \"-TH\" + str(threshold)\nprint(ID_string)\nprint('Test loss:', test_loss)\npredictions(y_pred_val, test_labels)",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "MNIST_DeepSets_Training.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "file_extension": ".py",
      "version": "3.5.4",
      "pygments_lexer": "ipython3",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}